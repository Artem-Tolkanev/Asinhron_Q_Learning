{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84a97a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt,sin,cos\n",
    "from numpy import array\n",
    "from numpy import linspace,zeros,float32\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd0a4224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    use_gpu = True\n",
    "    print(\"Using GPU\")\n",
    "else:\n",
    "    use_gpu = False\n",
    "FloatTensor = torch.cuda.FloatTensor if use_gpu else torch.FloatTensor\n",
    "DoubleTensor = torch.cuda.DoubleTensor if use_gpu else torch.DoubleTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_gpu else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if use_gpu else torch.ByteTensor\n",
    "Tensor = DoubleTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7008d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class theta:\n",
    "    def __init__(\n",
    "        self,\n",
    "        count_state = 16,\n",
    "        count_action = 5,\n",
    "    ):\n",
    "        self.count_state = count_state\n",
    "        self.count_action = count_action\n",
    "        self.matrix = np.zeros((count_action,count_state),dtype = np.float32)\n",
    "            \n",
    "    def __call__(self): return self.matrix\n",
    "    \n",
    "    def calc(\n",
    "        self,\n",
    "        s,\n",
    "        a,\n",
    "    ):\n",
    "        return np.matmul(a.transpose(),np.matmul(self.matrix,s))\n",
    "    \n",
    "    def add_state(\n",
    "        self,\n",
    "    ):\n",
    "        self.matrix = np.c_[self.matrix, np.zeros(self.count_action)]\n",
    "        self.count_state += 1\n",
    "        \n",
    "    def add_action(\n",
    "        self,\n",
    "    ):\n",
    "        self.matrix = np.r_[self.matrix, [np.zeros(self.count_state)]]\n",
    "        self.count_action += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0978fc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dots:\n",
    "    def __init__(\n",
    "        self,\n",
    "        array\n",
    "    ):\n",
    "        self.dim = len(array[0])\n",
    "        self.count = len(array[:,0])\n",
    "        self.array = array\n",
    "    def __call__(\n",
    "        self,\n",
    "    ): return self.array\n",
    "    def add(\n",
    "        self,\n",
    "        vec\n",
    "    ):\n",
    "        self.array = np.vstack((self(), vec))\n",
    "        self.count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "716715b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class func:\n",
    "    def __init__(\n",
    "        self,\n",
    "        basis_dots,\n",
    "        kind = 'frobenius_norm',\n",
    "    ):\n",
    "        self.basis = basis_dots\n",
    "        self.dim = basis_dots.dim\n",
    "        self.count = basis_dots.count\n",
    "        self.base_f = self.frobenius\n",
    "        \n",
    "    def __call__(self,): return self.frobenius_result()\n",
    "    \n",
    "    def add(\n",
    "        self,\n",
    "        vec\n",
    "    ):\n",
    "        self.basis.add(vec)\n",
    "        self.count += 1\n",
    "    \n",
    "    def frobenius(\n",
    "        self,\n",
    "        dot,\n",
    "    ):\n",
    "        return lambda x: np.power(np.divide(1.,\n",
    "            np.linalg.norm(x-dot),\n",
    "            out = np.ones_like([1.])*np.inf,\n",
    "            where = np.linalg.norm(x-dot)>self.dim/self.count\n",
    "            ),4)\n",
    "    \n",
    "    def frobenius_result(\n",
    "        self,\n",
    "    ):       \n",
    "        local_vect = lambda x: np.fromiter((self.base_f(b_v)(x) for b_v in self.basis())\n",
    "             ,self.basis().dtype)\n",
    "        norm = lambda x: np.sum(local_vect(x)) \n",
    "        normalized_local_vect = lambda x: np.divide(local_vect(x),\n",
    "            norm(x),\n",
    "            out = np.ones_like(local_vect(x)) / np.count_nonzero(local_vect(x) == np.inf),\n",
    "            where = local_vect(x)!=np.inf\n",
    "            )\n",
    "        return lambda x: normalized_local_vect(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1b394e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class replay_buffer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        state_dim = 16,\n",
    "        action_dim = 3,\n",
    "        round_len = 50,\n",
    "    ):\n",
    "        [x for x in range(round_len)]\n",
    "        self.value = dict.fromkeys([x for x in range(round_len)], \n",
    "                {\"state\":np.zeros((state_dim),dtype = float32),\n",
    "                   \"action\":np.zeros((action_dim),dtype = float32),\n",
    "                   \"state_new\":np.zeros((state_dim),dtype = float32),\n",
    "                   \"reward\":0.0})\n",
    "#         self.value = [{\"t\":x,\n",
    "#                    \"state\":np.zeros((state_dim),dtype = float64),\n",
    "#                    \"action\":np.zeros((action_dim),dtype = float64),\n",
    "#                    \"state_new\":np.zeros((state_dim),dtype = float64),\n",
    "#                    \"reward\":0.0} for x in range(round_len)]\n",
    "        \n",
    "    def __call__(self,): return self.value\n",
    "    \n",
    "    def state(self, t): return self.value[t][\"state\"]\n",
    "    def action(self, t): return self.value[t][\"action\"]\n",
    "    def reward(self, t): return self.value[t][\"reward\"]\n",
    "    \n",
    "    def replay_buffer_import(self,): return None    \n",
    "    def replay_buffer_export(self,): return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3a8dde9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import functools as f\n",
    "import time\n",
    "\n",
    "class agent:\n",
    "    def __init__(\n",
    "        self,\n",
    "        state_basis,\n",
    "        action_basis,\n",
    "        state_func_type = 'frobenius_norm',\n",
    "        action_func_type = 'frobenius_norm',\n",
    "        action_scale = sqrt(2.0),\n",
    "        gamma = 0.9,\n",
    "        greedy_rate = 0.1,\n",
    "        epsilon = 0.3,\n",
    "        replay_buffer_size = 50,\n",
    "        device = torch.device(\"cuda:0\"),\n",
    "    ):\n",
    "        self.s_f = func(state_basis, state_func_type)\n",
    "        self.a_f = func(action_basis, action_func_type)\n",
    "        self.Q = theta(state_basis.count, action_basis.count)\n",
    "        self.count_use = theta(state_basis.count, action_basis.count)\n",
    "        self.count_use.matrix += 1.\n",
    "        self.epoch_learn = 0\n",
    "        self.round_learn = 0\n",
    "        self.state = np.array([0.2, 0.3, 0.01, -0.05])\n",
    "        self.state_prev = None\n",
    "        self.action = None\n",
    "        self.reward = 0.\n",
    "        self.action_scale = action_scale\n",
    "        self.replay_buffer = replay_buffer(state_basis.dim, action_basis.dim, replay_buffer_size)\n",
    "        self.gamma = gamma\n",
    "        self.greedy_rate = greedy_rate\n",
    "        self.epsilon = epsilon\n",
    "        self.replay_buffer_size = replay_buffer_size\n",
    "        self.device = device\n",
    "    \n",
    "    def add_state(self):\n",
    "        self.s_f.add()\n",
    "        self.Q.add_state()\n",
    "        self.count_use.add_state()\n",
    "        self.count_use.matrix = np.where(count_use.matrix > 0.,count_use.matrix,1.)\n",
    "        \n",
    "    def add_action(self):\n",
    "        self.a_f.add()\n",
    "        self.Q.add_action()\n",
    "        self.count_use.add_action()\n",
    "        self.count_use.matrix = np.where(count_use.matrix > 0.,count_use.matrix,1.)\n",
    "        \n",
    "    def observe(self, state, reward):\n",
    "        self.state = state\n",
    "        self.reward = reward\n",
    "    \n",
    "    def policy(\n",
    "        self,\n",
    "        param = {\"type\":\"random\"},\n",
    "    ):\n",
    "        if param[\"type\"] == \"random\":\n",
    "            return (np.random.rand(self.a_f.dim) - 0.5) * 2.0 * self.action_scale\n",
    "        elif param[\"type\"] == \"pd\":\n",
    "            k = np.array([[-0.12, 0, -0.68, 0],\n",
    "                      [0, -0.12, 0, -0.68]])\n",
    "            return np.dot(k, self.state )\n",
    "        elif param[\"type\"] == \"greedy\":\n",
    "            greedy = random.choices(population=[True, False],\n",
    "                    weights=[self.greedy_rate, 1.0 - self.greedy_rate],\n",
    "                    k = 1)\n",
    "            if greedy[0]:\n",
    "                q_a_arr = np.fromiter(Q.calc(self.state, a) for a in self.a_f.basis())\n",
    "                action_max_arr = np.argwhere(q_a_arr == np.min(q_a_arr))\n",
    "                action_max_choice = random.choices(population = action_max_arr)\n",
    "                return self.a_f.basis()[action_max_choice]\n",
    "            else:\n",
    "                return self.policy()\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    #@f.lru_cache(maxsize=None)\n",
    "    def Q_update(\n",
    "        self,\n",
    "    ):\n",
    "#         p_1 = f.lru_cache(maxsize=None)(lambda t: np.outer(self.a_f()(self.replay_buffer()[t][\"action\"]),\n",
    "#                                  self.s_f()(self.replay_buffer()[t][\"state\"])\n",
    "#                                 ))\n",
    "#         p_1 = f.lru_cache(maxsize=None)(lambda t: torch.from_numpy(np.outer(self.a_f()(self.replay_buffer.action(t)),\n",
    "#                                  self.s_f()(self.replay_buffer.state(t))\n",
    "#                                 )).float().to(self.device))\n",
    "        \n",
    "#         p_2 = (1.0 + self.s_f.dim * self.a_f.dim)/(torch.from_numpy(self.count_use.matrix).float().to(self.device) + self.s_f.dim * self.a_f.dim)\n",
    "        \n",
    "#         filter_by_epsilon = f.lru_cache(maxsize=None)(lambda t: torch.from_numpy(np.where(p_1(t).detach().cpu().numpy() > self.epsilon,\n",
    "#                                                                                           1.0,0.0)).float().to(self.device))\n",
    "        \n",
    "#         p = f.lru_cache(maxsize=None)(lambda t: torch.multiply(filter_by_epsilon(t),\n",
    "#                                   torch.multiply(p_1(t), p_2)))\n",
    "        \n",
    "#         T = f.lru_cache(maxsize=None)(lambda t: self.replay_buffer.reward(t) + self.gamma * np.min(np.matmul(self.Q.matrix,self.s_f()(self.replay_buffer.state(t)))))\n",
    "\n",
    "#         #ticks_num = sum([filter_by_epsilon(t) for t in range(self.replay_buffer_size)])\n",
    "#         time1 = time.time()\n",
    "#         ticks_num = f.reduce(lambda x, y: x + filter_by_epsilon(y), range(self.replay_buffer_size)) \n",
    "#         time2 = time.time()\n",
    "#         print('time diff ticks_num', time2-time1)\n",
    "#         ticks_num_divided = torch.from_numpy(np.divide(1.0,\n",
    "#                          ticks_num.detach().cpu().numpy(),\n",
    "#                          out = np.zeros_like(ticks_num.detach().cpu().numpy()),\n",
    "#                          where=ticks_num.detach().cpu().numpy()!=0.0)).float().to(self.device)\n",
    "#         time3 = time.time()\n",
    "#         print('time diff ticks_num', time3-time2)\n",
    "#         #------------------------------------------------------------------------------------------\n",
    "#         #update:\n",
    "#         self.Q.matrix = (torch.multiply(ticks_num_divided,\n",
    "#                             f.reduce(lambda x, y: x +  p(y) * T(y),\n",
    "#                                      range(self.replay_buffer_size))) +  torch.multiply(torch.from_numpy(self.Q.matrix).float().to(self.device),\n",
    "#                               ( 1.0 - torch.multiply(ticks_num_divided, f.reduce(lambda x, y: x + p(y), range(self.replay_buffer_size) )))  )).detach().cpu().numpy()                                                                                   \n",
    "#         time4 = time.time()\n",
    "#         print('time diff ticks_num', time4-time3)\n",
    "#         self.count_use.matrix = self.count_use.matrix + np.where(ticks_num.detach().cpu().numpy() > 0.0, 1, 0)\n",
    "        #------------------------------------------------------------------------------------------\n",
    "        p_1 = f.lru_cache(maxsize=None)(lambda t: np.outer(self.a_f()(self.replay_buffer.action(t)),\n",
    "                                 self.s_f()(self.replay_buffer.state(t))\n",
    "                                ))\n",
    "        \n",
    "        p_2 = (1.0 + self.s_f.dim * self.a_f.dim)/(self.count_use.matrix + self.s_f.dim * self.a_f.dim)\n",
    "        \n",
    "        filter_by_epsilon = f.lru_cache(maxsize=None)(lambda t: np.where(p_1(t) > self.epsilon,\n",
    "                                                                                          1.0,0.0))\n",
    "        \n",
    "        p = f.lru_cache(maxsize=None)(lambda t: np.multiply(filter_by_epsilon(t),\n",
    "                                  np.multiply(p_1(t), p_2)))\n",
    "        \n",
    "        T = f.lru_cache(maxsize=None)(lambda t: self.replay_buffer.reward(t) + self.gamma * np.min(np.matmul(self.Q.matrix,self.s_f()(self.replay_buffer.state(t)))))\n",
    "\n",
    "        #ticks_num = sum([filter_by_epsilon(t) for t in range(self.replay_buffer_size)])\n",
    "        time1 = time.time()\n",
    "        ticks_num = f.reduce(lambda x, y: x + filter_by_epsilon(y), range(self.replay_buffer_size)) \n",
    "        time2 = time.time()\n",
    "        print('time diff ticks_num', time2-time1)\n",
    "        ticks_num_divided = np.divide(1.0,\n",
    "                         ticks_num,\n",
    "                         out = np.zeros_like(ticks_num),\n",
    "                         where=ticks_num!=0.0)\n",
    "        time3 = time.time()\n",
    "        print('time diff ticks_num', time3-time2)\n",
    "        #------------------------------------------------------------------------------------------\n",
    "        #update:\n",
    "        self.Q.matrix = (np.multiply(ticks_num_divided,\n",
    "                            f.reduce(lambda x, y: x +  p(y) * T(y),\n",
    "                                     range(self.replay_buffer_size))) +  np.multiply(self.Q.matrix,\n",
    "                              ( 1.0 - np.multiply(ticks_num_divided, f.reduce(lambda x, y: x + p(y), range(self.replay_buffer_size) )))  ))                                                                                  \n",
    "        time4 = time.time()\n",
    "        print('time diff ticks_num', time4-time3)\n",
    "        self.count_use.matrix = self.count_use.matrix + np.where(ticks_num > 0.0, 1, 0)\n",
    "        #------------------------------------------------------------------------------------------\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ac67eb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_dots = dots(array(\n",
    "    [[1.0, 1.0]\n",
    "    , [1.0, 0.0]\n",
    "    , [1.0, -1.0]\n",
    "    , [0.0, 1.0]\n",
    "    , [0.0, 0.0]\n",
    "    , [0.0, -1.0]\n",
    "    , [-1.0, 1.0]\n",
    "    , [-1.0, 0.0]\n",
    "    , [-1.0, -1.0]\n",
    "   ],dtype = np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b7ed36e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "x_partition = [-5.0, -2.0, -1.0 , -0.7, -0.5, -0.3, -0.2, -0.1, 0.1, 0.2, 0.3, 0.5, 0.7, 1.0, 2.0, 5.0]\n",
    "y_partition = [-5.0, -2.0, -1.0 , -0.7, -0.5, -0.3, -0.2, -0.1, 0.1, 0.2, 0.3, 0.5, 0.7, 1.0, 2.0, 5.0]\n",
    "vx_partition = [-2.0, -1.5, -1.0, -0.5, 0.5, 1.0, 1.5, 2.0]\n",
    "vy_partition = [-2.0, -1.5, -1.0, -0.5, 0.5, 1.0, 1.5, 2.0]\n",
    "\n",
    "iterables = [x_partition, y_partition, vx_partition, vy_partition]\n",
    "\n",
    "state_dots = dots(array(\n",
    "    [t for t in itertools.product(*iterables)],dtype = np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3901ae15",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_one = agent(state_dots, action_dots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2942cec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_one.Q()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3ba00033",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:39: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time diff ticks_num 79.87548327445984\n",
      "time diff ticks_num 0.0009980201721191406\n",
      "time diff ticks_num 81.701815366745\n"
     ]
    }
   ],
   "source": [
    "agent_one.Q_update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a8480df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:39: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time diff ticks_num 1.593968152999878\n",
      "[1.7913057e-07 1.9044984e-07 1.9920503e-07 ... 1.9920503e-07 1.9044984e-07\n",
      " 1.7913057e-07]\n"
     ]
    }
   ],
   "source": [
    "time1 = time.time()\n",
    "agent_one.s_f()(np.array([0., 0., 0., 0.]))\n",
    "time2 = time.time()\n",
    "print('time diff ticks_num', time2-time1)\n",
    "print(agent_one.s_f()(np.array([0., 0., 0., 0.])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ab1eb53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:39: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "aa = agent_one.s_f()(np.array([0., 0., 0., 0.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933a5243",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
